# -*- coding: utf-8 -*-
"""newLearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IyaXI1RuFEZZ1PlF9Ag4mJqWG2g91ktu
"""

import os
import librosa
import sklearn
import numpy as np
import matplotlib.pyplot as plt
import random
import json
from collections import OrderedDict

import tensorflow as tf
import keras
from keras import layers, models ,Model ,Input
from keras.layers import Dense, Flatten, Activation, BatchNormalization
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import sys
sys.path.append('/content/gdrive/MyDrive/VoiceRecognition/main')
print(sys.path)

from training1 import *

def newData_learn(model_dir, record_dir):
  record = record_dir
  base_model = models.load_model(model_dir)
  record_list = os.listdir(record) 

  record_data = []
  record_target = []
   
  for i, (root, dirs, files) in enumerate (os.walk(record)):
    for file in files :
      if '.wav'  not in file in file :
        continue
      else :
        audio_path = os.path.join(root,file)
        mfcc, delta = MFCC(audio_path)
        mfcc = mfcc.astype(float)
        dirname = os.path.dirname(audio_path) 
        record_data.append(mfcc)
        record_target.append(dirname)

  padding(record_data,base_model.input)
  record_data = np.array(record_data)

  re_encoder = LabelEncoder()
  re_encoder.fit(record_target)
  retarget_encoded = re_encoder.transform(record_target)
  print(record_target, '==>', retarget_encoded)
  
  #user_info encoding 저장
  enc_userinfo=OrderedDict()
  user_target=[]

  for dirname in os.listdir(record_dir):
    user_target.append(dirname)

  user_encoder = LabelEncoder()
  user_encoder.fit(user_target)
  reusertarget_encoded = user_encoder.transform(user_target)

  for i, label in enumerate(user_encoder.classes_):
      # print(i, '->', label)
      enc_userinfo[i]=label

  print(user_target, '==>', reusertarget_encoded)
  print(json.dumps(enc_userinfo, ensure_ascii=False, indent="\t"))

  with open("/content/gdrive//MyDrive/VoiceRecognition/static/UserInfo/user_info.json", 'w', encoding='utf-8') as make_file:
    json.dump(enc_userinfo, make_file, indent="\t")

  record_target = tf.keras.utils.to_categorical(np.array(retarget_encoded))

  rectrain_x, recval_x, rectrain_y, recval_y = train_test_split(record_data, record_target, test_size=0.3, shuffle=True, stratify=record_target, random_state=42)
  rectrain_x = np.expand_dims(rectrain_x, -1)
  recval_x = np.expand_dims(recval_x, -1)
  print("record train size : ",rectrain_x.shape[0])

  net = Dense(rectrain_y.shape[1], activation='softmax' ,name="dense_a")(base_model.layers[-2].output)
  model = Model(inputs = base_model.input, outputs = net)

  model.summary()

  model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

  model.fit(rectrain_x,
            rectrain_y,
            epochs=50,
            batch_size=32,
            verbose=1,
            validation_data=(recval_x, recval_y),
            )
  
  return model,record_target

def make_predx(test_dir, input_shape):
  test_data = []
  
  for i, (root, dirs, files) in enumerate (os.walk(test_dir)):
    for file in files :
      if '.wav'  not in file in file :
        continue
      else :
        audio_path = os.path.join(root,file)
        mfcc, delta = MFCC(audio_path)
        mfcc = mfcc.astype(float)
        test_data.append(mfcc)

  padding(test_data,input_shape)
  test_data = np.array(test_data)

  test_data = np.expand_dims(test_data, -1)

  return test_data

def model_update(model_path, record_path):
  model,record_target= newData_learn(model_path,record_path)

  model.save("/content/gdrive//MyDrive/VoiceRecognition/main/demo_model.h5")