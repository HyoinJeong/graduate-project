{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"newLearn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import librosa\n","import sklearn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random"],"metadata":{"id":"N_uynUYbBYyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","from keras import layers, models ,Model ,Input\n","from keras.layers import Dense, Flatten, Activation, BatchNormalization\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"I_RvRE3dBrVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY8YsWHaBTNE","executionInfo":{"status":"ok","timestamp":1654294989570,"user_tz":-540,"elapsed":21724,"user":{"displayName":"민경","userId":"14535142896106184098"}},"outputId":"2e87e469-6a63-4c67-e5c9-52f07144d7e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/VoiceRecognition/main')\n","print(sys.path)"],"metadata":{"id":"rxhKtlZeFFm2","executionInfo":{"status":"ok","timestamp":1654294992332,"user_tz":-540,"elapsed":566,"user":{"displayName":"민경","userId":"14535142896106184098"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b6bbaee-fd77-4619-d1b6-d10984c1c21a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/gdrive/MyDrive/VoiceRecognition/main']\n"]}]},{"cell_type":"code","source":["from training1 import *"],"metadata":{"id":"Qk9m5-PLG0dF","executionInfo":{"status":"error","timestamp":1654295038273,"user_tz":-540,"elapsed":292,"user":{"displayName":"민경","userId":"14535142896106184098"}},"colab":{"base_uri":"https://localhost:8080/","height":318},"outputId":"431ca951-6d06-4a18-9919-04d4dbf1d420"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-8a84132f3142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'training1'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def newData_learn(model_dir, record_dir):\n","  record = record_dir\n","  base_model = models.load_model(model_dir)\n","  record_list = os.listdir(record) \n","\n","  record_data = []\n","  record_target = []\n","   \n","  for i, (root, dirs, files) in enumerate (os.walk(record)):\n","    for file in files :\n","      if '.wav'  not in file in file :\n","        continue\n","      else :\n","        audio_path = os.path.join(root,file)\n","        mfcc, delta = MFCC(audio_path)\n","        mfcc = mfcc.astype(float)\n","        dirname = os.path.dirname(audio_path) \n","        record_data.append(mfcc)\n","        record_target.append(dirname)\n","\n","  padding(record_data,base_model.input)\n","  record_data = np.array(record_data)\n","\n","  re_encoder = LabelEncoder()\n","  re_encoder.fit(record_target)\n","  retarget_encoded = re_encoder.transform(record_target)\n","  print(record_target, '==>', retarget_encoded)\n","\n","  record_target = tf.keras.utils.to_categorical(np.array(retarget_encoded))\n","\n","  rectrain_x, recval_x, rectrain_y, recval_y = train_test_split(record_data, record_target, test_size=0.3, shuffle=True, stratify=record_target, random_state=42)\n","  rectrain_x = np.expand_dims(rectrain_x, -1)\n","  recval_x = np.expand_dims(recval_x, -1)\n","  print(\"record train size : \",rectrain_x.shape[0])\n","\n","  net = Dense(len(record_list), activation='softmax' ,name=\"dense_a\")(base_model.layers[-2].output)\n","  model2 = Model(inputs = base_model.input, outputs = net)\n","\n","  model2.summary()\n","\n","  model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","  model2.fit(rectrain_x,\n","            rectrain_y,\n","            epochs=50,\n","            batch_size=32,\n","            verbose=1,\n","            validation_data=(recval_x, recval_y),\n","            )\n","  \n","  return model2\n"],"metadata":{"id":"zhj90JJnVUwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pred_data(test_dir, input_shape):\n","  test_data = []\n","  \n","  for i, (root, dirs, files) in enumerate (os.walk(test_dir)):\n","    for file in files :\n","      if '.wav'  not in file in file :\n","        continue\n","      else :\n","        audio_path = os.path.join(root,file)\n","        mfcc, delta = MFCC(audio_path)\n","        mfcc = mfcc.astype(float)\n","        test_data.append(mfcc)\n","\n","  padding(test_data,input_shape)\n","  test_data = np.array(test_data)\n","\n","  test_data = np.expand_dims(test_data, -1)\n","\n","  return test_data"],"metadata":{"id":"VbDWAUDCXj8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model3 = newData_learn('/content/gdrive/MyDrive/model/best_model.h5','/content/gdrive/MyDrive/VoiceRecognition/data/Recording/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"US0wI874VQKX","executionInfo":{"status":"error","timestamp":1654295056666,"user_tz":-540,"elapsed":359,"user":{"displayName":"민경","userId":"14535142896106184098"}},"outputId":"837210c0-0363-4e10-a2cd-04b0ea3c42fd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d45ed01b3d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewData_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/model/best_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/VoiceRecognition/data/Recording/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-22470e4313cd>\u001b[0m in \u001b[0;36mnewData_learn\u001b[0;34m(model_dir, record_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnewData_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mrecord_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/gdrive/MyDrive/model/best_model.h5"]}]},{"cell_type":"code","source":["test_x = pred_data('/content/gdrive/MyDrive/VoiceRecognition/data/Recording/zzds0623/',(20,262,1))\n","pred = np.argmax(model3.predict(test_x), axis=-1)\n","print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"XTxtHkTue_tW","executionInfo":{"status":"error","timestamp":1654295075895,"user_tz":-540,"elapsed":311,"user":{"displayName":"민경","userId":"14535142896106184098"}},"outputId":"4409c909-2fe0-4591-ef42-82a4de8b61c5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ab62b4a75972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/VoiceRecognition/data/Recording/zzds0623/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m262\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ed93dd394a90>\u001b[0m in \u001b[0;36mpred_data\u001b[0;34m(test_dir, input_shape)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'padding' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"s9hhNKk0je0y"},"execution_count":null,"outputs":[]}]}